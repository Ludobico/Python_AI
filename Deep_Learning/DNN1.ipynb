{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 딥러닝이란\n",
    "* DNN(Deep Neural Network)\n",
    "    * 개념소개\n",
    "        * 딥러닝의 기본이 되는 인공신경망(ANN)의 개념은 1943년에 신경생리학자 워렌 맥 컬럭과 수학자 월터 피트가 처음 제안하였다.\n",
    "        * 여러 겹의 신경망 레이어를 쌓아 올린 형태이고, 레이어는 노드(Node)라는 유닛의 집합이다.\n",
    "        * 노드는 바로 앞의 레이어들로부터 값을 전달받아 각 값들에 가중치를 곱한 후 모두 더해 새로운 값을 만든다. 그리고 새로운 값은 미리 지정해둔 노드의 활성 함수를 통해 변환된 후 다음 레이어로 전달된다. 그리고 다음 레이어에서는 같은 과정을 반복한다.\n",
    "        * 활성 함수는 딥러닝을 비선형 모델로 만들어 성능을 향상시킨다.\n",
    "        * 아이리스 데이터셋을 예로 들어 딥러닝 모델을 그림으로 표현하면 아래와 같다.\n",
    "            - input layer, hidden layer, output layer로 구성된다.\n",
    "            - input layer: 값을 입력받는 역할만 하는 레이어이다. 노드의 개수는 피쳐의 개수 와 동일하다.\n",
    "            - hidden layer: 모델의 성능을 좌우하는 중요한 레이어다. 딥러닝에서는 히든 레이어의 개수와 각 레이어의 노드 개수가 하이퍼 파라미터다.\n",
    "            - output layer: 최종 결과를 산출하는 레이어다. 분류 분석에서는 클래스의 개수 만큼 output layer의 노드 수를 지정한다. 회귀 문제에서는 output layer의 노드는 1이다.\n",
    "* 딥러닝의 개념\n",
    "    * 퍼셉트론(Perceptron)\n",
    "        * 프랑크 로젠블라트가 1957년에 제안한 초기 형태의 인공 신경망으로 다수의 입력으로부터 하나의 결과를 내보내는 알고리즘이다.\n",
    "        * 퍼셉트론은 실제 뇌를 구성하는 신경 세포 뉴런의 동작과 유사한데, 신경 세포 뉴런의 그림을 보면 뉴런은 가지돌기에서 신호를 받아들이고, 이 신호가 일정치 이상의 크기를 가지면 축삭돌기를 통해서 신호를 전달한다.\n",
    "        * 퍼셉트론의 그림을 보면 신경 세포 뉴런의 입력 신호와 출력 신호가 퍼셉트론에서 각각 입력값과 출력값에 해당된다.\n",
    "        * 각각의 입력값에는 각각의 가중치가 존재하는데, 이때 가중치의 값이 크면 클수록 해당 입력값이 중요하다는 것을 의미한다.\n",
    "        * 이 임계치값을 수식으로 표현할 때는 보통 세타로 표현한다.\n",
    "        * 각 입력값이 가중치와 곱해져서 인공 뉴런에 보내지고, 각 입력값과 그에 해당하는 가중치의 곱의 전체 합이 임계치(threshold)를 넘으면 종착지에 있는 인공 뉴런은 출력 신호로서 1을 출력하고, 그렇지 않을 경우에는 0을 출력한다. 이러한 함수를 계단 함수라고한다.\n",
    "#### 단층 퍼셉트론 (Single-Layer Perceptron)\n",
    "* 구조\n",
    "    * 값을 보내는 단계와 값을 받아서 출력하는 두 단계로만 이루어진다.\n",
    "    * 이 각 단계를 보통 층(layer)라고 부르며, 이 두개의 층을 입력층(input layer)과 출력층(output layer)라고 한다.\n",
    "    * 단층 퍼셉트론을 이용하면 AND,NAND,OR 게이트를 쉽게 구현할 수 있다. 게이트 연산에 쓰이는 것은 두 개의 입력 값과 하나의 출력 값이다.\n",
    "* XOR 게이트\n",
    "    * 단층 퍼셉트론은 AND 게이트, NAND 게이트, OR 게이트 또한 구현할 수 있다. 하지만 단층 퍼셉트론으로 구현이 불가능한 게이트가 있는데 바로 XOR 게이트다.\n",
    "    * XOR 게이트는 입력값 두 개가 서로 다른 값을 갖고 있을 때에만 출력값이 1이 되고, 입력값 두개가 서로 같은 값을 가지면 출력값이 0이 되는 게이트이다.\n",
    "* XOR 문제\n",
    "    * 논리게이트 AND / OR / NAND / XOR\n",
    "        - AND / OR / NAND / XOR 내부 구조는 선형회귀 값을 계산하는 Regression과 Sigmoid 함수 값을 출력하는 Classification 으로 구성된 시스템으로 나타낼 수 있다.\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AND_gate(x1,x2): #x1, x2 둘 다 1이상이면 1 아니면 0\n",
    "    w1 = 0.5\n",
    "    w2 = 0.5\n",
    "    b = -0.7\n",
    "    result = x1*w1 + x2*w2 + b\n",
    "    if result <= 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "    \n",
    "def NAND_gate(x1, x2): #x1, x2 둘 다 1이상이면 0 아니면 1\n",
    "    w1=-0.5\n",
    "    w2=-0.5\n",
    "    b=0.7\n",
    "    result = x1*w1 + x2*w2 + b\n",
    "    if result <= 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "    \n",
    "def OR_gate(x1, x2): #x1, x2 둘 중 하나만 1이상이면 1 아니면 0\n",
    "    w1=0.6\n",
    "    w2=0.6\n",
    "    b=-0.5\n",
    "    result = x1*w1 + x2*w2 + b\n",
    "    if result <= 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 논리게이트 (Logic gate) 클래스 구현\n",
    "import numpy as np\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1./ (1. + np.exp(-x))\n",
    "\n",
    "def numerical_derivative(f,x):\n",
    "    delta_x = 1e-4 #0.0001\n",
    "    grad = np.zeros_like(x)\n",
    "    \n",
    "    it = np.nditer(x, flags=['multi_index'], op_flags=['readwrite'])\n",
    "    \n",
    "    while not it.finished:\n",
    "        idx = it.multi_index\n",
    "        tmp_val = x[idx]\n",
    "        x[idx] = float(tmp_val) + delta_x\n",
    "        fx1 = f(x) #f(x+delta_x)\n",
    "        \n",
    "        x[idx] = float(tmp_val) - delta_x\n",
    "        fx2 = f(x)\n",
    "        grad[idx] = (fx1 - fx2) / (2*delta_x)\n",
    "        \n",
    "        x[idx] = tmp_val\n",
    "        it.iternext()\n",
    "        \n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogicGate:\n",
    "    def __init__(self, gate_name, xdata, tdata):\n",
    "        self.name = gate_name\n",
    "        self.xdata = xdata.reshape(4,2) #입력 데이터 초기화\n",
    "        self.tdata = tdata.reshape(4,1) #정답 데이터 초기화\n",
    "        self.w = np.random.rand(self.xdata.shape[1], 1) #가중치 w 초기화\n",
    "        self.b = np.random.rand(1) #bias b 초기화\n",
    "        self.learning_rate = 1e-2 #학습률 learning rate 초기화\n",
    "        \n",
    "    def loss_func(self):\n",
    "        delta = 1e-7 # log 무한대 발산 방지\n",
    "        z = np.dot(self.xdata, self.w) + self.b\n",
    "        y = sigmoid(z)\n",
    "        return -np.sum(self.tdata * np.log(y+delta) + (1-self.tdata) * np.log((1 - y))+delta)\n",
    "    \n",
    "    def train(self): #경사하강법 이용하여 w,b 업데이트\n",
    "        f = lambda x: self.loss_func()\n",
    "        print('Initial loss value =', self.loss_func())\n",
    "        for step in range(8001):\n",
    "            self.w -= self.learning_rate * numerical_derivative(f, self.w)\n",
    "            self.b -= self.learning_rate * numerical_derivative(f, self.b)\n",
    "            # if (step % 1000 == 0):\n",
    "            #     print('step =', step, 'loss value =', self.loss_func())\n",
    "                \n",
    "    def predict(self, input_data): # 미래 값 예측\n",
    "        z = np.dot(input_data, self.w) + self.b\n",
    "        y = sigmoid(z)\n",
    "        if y > 0.5:\n",
    "            result = 1\n",
    "        else:\n",
    "            result = 0\n",
    "        return y, result\n",
    "    \n",
    "    def accuracy(self, test_xdata, test_tdata): #정확도 예측 함수\n",
    "        matched_list = []\n",
    "        not_matched_list = []\n",
    "        for index in range(len(xdata)):\n",
    "            (real_val, logical_val) = self.predict(test_xdata[index])\n",
    "            if logical_val == test_tdata[index]:\n",
    "                matched_list.append(index)\n",
    "            else:\n",
    "                not_matched_list.append(index)\n",
    "        accuracy_val = len(matched_list) / len(test_xdata)\n",
    "        \n",
    "        return accuracy_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial loss value = 3.946749824221474\n",
      "[0 0] = 0\n",
      "[0 1] = 0\n",
      "[1 0] = 0\n",
      "[1 1] = 1\n",
      "Accuracy =>  1.0\n"
     ]
    }
   ],
   "source": [
    "#AND 논리 게이트 검증\n",
    "xdata = np.array([[0,0], [0,1], [1,0], [1,1]])\n",
    "tdata = np.array([0,0,0,1])\n",
    "AND_obj = LogicGate('AND_GATE', xdata, tdata)\n",
    "AND_obj.train()\n",
    "\n",
    "test_xdata = np.array([ [0,0], [0,1], [1,0], [1,1] ])\n",
    "for input_data in test_xdata:\n",
    "    (sigmoid_val, logical_val) = AND_obj.predict(input_data)\n",
    "    print(input_data, '=', logical_val)\n",
    "    \n",
    "test_tdata = np.array([ 0, 0, 0, 1])\n",
    "accuracy_ret = AND_obj.accuracy(test_xdata, test_tdata)\n",
    "print(\"Accuracy => \", accuracy_ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial loss value = 1.7567142871616515\n",
      "[0 0]  =  0\n",
      "[0 1]  =  1\n",
      "[1 0]  =  1\n",
      "[1 1]  =  1\n",
      "--------------------\n",
      "Accuracy =>  1.0\n"
     ]
    }
   ],
   "source": [
    "#or 논리 게이트 검증\n",
    "xdata = np.array([ [0, 0], [0, 1], [1, 0], [1, 1] ]) \n",
    "tdata = np.array([0, 1, 1, 1])\n",
    "OR_obj = LogicGate(\"OR_GATE\", xdata, tdata) \n",
    "OR_obj.train() \n",
    "test_xdata = np.array([ [0, 0], [0, 1], [1, 0], [1, 1] ])\n",
    "for input_data in test_xdata:\n",
    "    (sigmoid_val, logical_val) = OR_obj.predict(input_data) \n",
    "    print(input_data, \" = \", logical_val) \n",
    "print('--------------------')\n",
    "test_tdata = np.array([ 0, 1, 1, 1])\n",
    "accuracy_ret = OR_obj.accuracy(test_xdata, test_tdata)\n",
    "print(\"Accuracy => \", accuracy_ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial loss value = 2.708254832781196\n",
      "[0 0]  =  1\n",
      "[0 1]  =  1\n",
      "[1 0]  =  1\n",
      "[1 1]  =  0\n",
      "--------------------\n",
      "Accuracy =>  1.0\n"
     ]
    }
   ],
   "source": [
    "#NAND 논리게이트 검증\n",
    "xdata = np.array([ [0, 0], [0, 1], [1, 0], [1, 1] ]) \n",
    "tdata = np.array([1, 1, 1, 0])\n",
    "NAND_obj = LogicGate(\"NAND_GATE\", xdata, tdata) \n",
    "NAND_obj.train() \n",
    "\n",
    "test_xdata = np.array([ [0, 0], [0, 1], [1, 0], [1, 1] ])\n",
    "for input_data in test_xdata:\n",
    "    (sigmoid_val, logical_val) = NAND_obj.predict(input_data) \n",
    "    print(input_data, \" = \", logical_val)\n",
    "\n",
    "print('--------------------') \n",
    "test_tdata = np.array([ 1, 1, 1, 0])\n",
    "accuracy_ret = NAND_obj.accuracy(test_xdata, test_tdata)\n",
    "print(\"Accuracy => \", accuracy_ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial loss value = 3.0226336570575527\n",
      "[0 0]  =  0\n",
      "[0 1]  =  0\n",
      "[1 0]  =  0\n",
      "[1 1]  =  1\n",
      "--------------------\n",
      "Accuracy =>  0.25\n"
     ]
    }
   ],
   "source": [
    "#XOR 논리 게이트 검증\n",
    "xdata = np.array([ [0, 0], [0, 1], [1, 0], [1, 1] ]) \n",
    "tdata = np.array([0, 1, 1, 0])\n",
    "XOR_obj = LogicGate(\"XOR_GATE\", xdata, tdata) \n",
    "XOR_obj.train()\n",
    "\n",
    "test_xdata = np.array([ [0, 0], [0, 1], [1, 0], [1, 1] ])\n",
    "for input_data in test_xdata:\n",
    "    (sigmoid_val, logical_val) = XOR_obj.predict(input_data) \n",
    "    print(input_data, \" = \", logical_val)\n",
    "\n",
    "print('--------------------') \n",
    "test_tdata = np.array([ 0, 1, 1, 0])\n",
    "accuracy_ret = XOR_obj.accuracy(test_xdata, test_tdata)\n",
    "print(\"Accuracy => \", accuracy_ret)\n",
    "\n",
    "# 학습을 마친 후에 총 4개의 데이터(test_data)에 대한 predict() 메서드의 예측 값을 출력해보면 검증결과에 나타난 것처럼\n",
    "# XOR 논리 게이트 각 입력 값에 대해 결과값이 일치하지 않는다. 즉 XOR 논리게이트는 우리가 알아보았던 분류 알고리즘만으로는\n",
    "# 분류하기 어렵다는 것을 알 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial loss value = 3.759659399157568\n",
      "Initial loss value = 2.143483369101844\n",
      "Initial loss value = 2.774608472486059\n",
      "[0 0] = 0\n",
      "[0 1] = 1\n",
      "[1 0] = 1\n",
      "[1 1] = 0\n"
     ]
    }
   ],
   "source": [
    "#XOR 논리게이트\n",
    "\n",
    "xdata = np.array([[0,0], [0,1], [1,0], [1,1]])\n",
    "tdata = np.array([0,0,0,1])\n",
    "AND_obj = LogicGate('AND_GATE', xdata, tdata)\n",
    "AND_obj.train()\n",
    "\n",
    "xdata = np.array([ [0, 0], [0, 1], [1, 0], [1, 1] ]) \n",
    "tdata = np.array([0, 1, 1, 1])\n",
    "OR_obj = LogicGate(\"OR_GATE\", xdata, tdata) \n",
    "OR_obj.train()\n",
    "\n",
    "xdata = np.array([ [0, 0], [0, 1], [1, 0], [1, 1] ]) \n",
    "tdata = np.array([1, 1, 1, 0])\n",
    "NAND_obj = LogicGate(\"NAND_GATE\", xdata, tdata) \n",
    "NAND_obj.train()\n",
    "\n",
    "input_data = np.array([ [0,0], [0,1], [1,0], [1,1] ])\n",
    "s1 = []\n",
    "s2 = []\n",
    "new_input_data = []\n",
    "final_output = []\n",
    "\n",
    "for index in range(len(input_data)):\n",
    "    s1 = NAND_obj.predict(input_data[index])\n",
    "    s2 = OR_obj.predict(input_data[index])\n",
    "    new_input_data.append(s1[-1])\n",
    "    new_input_data.append(s2[-1])\n",
    "    (sigmoid_val, logical_val) = AND_obj.predict(np.array(new_input_data))\n",
    "    final_output.append(logical_val)\n",
    "    new_input_data = []\n",
    "    \n",
    "for index in range(len(input_data)):\n",
    "    print(input_data[index], '=', final_output[index])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9 (tags/v3.7.9:13c94747c7, Aug 17 2020, 18:58:18) [MSC v.1900 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9cc4cb84d376c55cbcefbb2577a30e93afba84ecdcb02495984b572f007c87af"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
