{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from symbol import xor_expr\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.callbacks import EarlyStopping\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "csv = pd.read_csv('../../../AI머신러닝데이터/bmi.csv')\n",
    "\n",
    "csv['weight'] /= 100\n",
    "csv['height'] /= 200\n",
    "x = csv[['weight', 'height']].to_numpy()\n",
    "\n",
    "bclass = {'thin':[1,0,0], 'normal':[0,1,0], 'fat':[0,0,1]}\n",
    "y = np.empty((20000,3))\n",
    "for i,v in enumerate(csv['label']):\n",
    "    y[i] = bclass[v]\n",
    "    \n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.3,random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14000, 2)\n",
      "(6000, 2)\n",
      "(14000, 3)\n",
      "(6000, 3)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_train = x_test[1:3001]\n",
    "y_test_train = y_test[1:3001]\n",
    "x_test_test = x_test[3001:6001]\n",
    "y_test_test = y_test[3001:6001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3000, 2)\n",
      "(3000, 3)\n",
      "(2999, 2)\n",
      "(2999, 3)\n"
     ]
    }
   ],
   "source": [
    "print(x_test_train.shape)\n",
    "print(y_test_train.shape)\n",
    "print(x_test_test.shape)\n",
    "print(y_test_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002C6C4A9AB88> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002C6C4A9AB88> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.4504 - accuracy: 0.8373\n",
      "Epoch 2/20\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.1413 - accuracy: 0.9568\n",
      "Epoch 3/20\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.1151 - accuracy: 0.9575\n",
      "Epoch 4/20\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.0857 - accuracy: 0.9682\n",
      "Epoch 5/20\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.0783 - accuracy: 0.9693\n",
      "Epoch 6/20\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.0759 - accuracy: 0.9682\n",
      "Epoch 7/20\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.0658 - accuracy: 0.9745\n",
      "Epoch 8/20\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.0697 - accuracy: 0.9722\n",
      "Epoch 9/20\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.0615 - accuracy: 0.9749\n",
      "Epoch 10/20\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.0639 - accuracy: 0.9734\n",
      "Epoch 11/20\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.0578 - accuracy: 0.9756\n",
      "Epoch 12/20\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.0691 - accuracy: 0.9704\n",
      "Epoch 13/20\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.0532 - accuracy: 0.9778\n",
      "Epoch 14/20\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.0606 - accuracy: 0.9730\n",
      "Epoch 15/20\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.0568 - accuracy: 0.9759\n",
      "Epoch 16/20\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.0510 - accuracy: 0.9789\n",
      "Epoch 17/20\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.0504 - accuracy: 0.9787\n",
      "Epoch 18/20\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.0562 - accuracy: 0.9757\n",
      "Epoch 19/20\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.0450 - accuracy: 0.9819\n",
      "Epoch 20/20\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.0471 - accuracy: 0.9806\n"
     ]
    }
   ],
   "source": [
    "# 모델 구조 정의하기\n",
    "model = Sequential()\n",
    "model.add(Dense(512, input_shape=(2,))) #input_shape(2,) 는 각각 height와 weight임\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(3))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "hist = model.fit(x_train,y_train, batch_size=100, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188/188 [==============================] - 0s 2ms/step - loss: 0.0314 - accuracy: 0.9920\n",
      "[0.031423550099134445, 0.9919999837875366]\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test,y_test)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x000002C6C5E1C8B8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x000002C6C5E1C8B8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x000002C6C73190D8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x000002C6C73190D8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "INFO:tensorflow:Assets written to: bmi_test.pkl\\assets\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np\n",
    "\n",
    "model.save('bmi_test.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_load_model = tf.keras.models.load_model('bmi_test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002C6C72E7E58> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002C6C72E7E58> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0309 - accuracy: 0.9920\n",
      "[0.03088216297328472, 0.9919973611831665]\n"
     ]
    }
   ],
   "source": [
    "testscore = new_load_model.evaluate(x_test_test,y_test_test)\n",
    "print(testscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.9 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "90ac13e2ffd2fb0a306c90461e8e391bceeb8ea777ddbefad745a048bb7968fd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
