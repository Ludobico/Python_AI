{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 다중 선형 회귀\n",
    "앞서 배운 x가 1개인 선형을 단순 선형 회귀(Simple Linear Regression)이라고 합니다.\n",
    "이번 챕터에서는 다수의 x로부터 y를 예측하는 다중 선형 회귀에 대해서 이해합니다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터에 대한 이해(Data Definition)\n",
    "다음과 같은 훈련 데이터가 있습니다. 앞서 배운 단순 선형 회귀와 다른 점은 독립 변수 x의 개수가 이제 1개가 아닌 3개라는 점입니다. 3개의 퀴즈 점수로부터 최종 점수를 예측하는 모델을 만들어보겠습니다.  \n",
    "\n",
    "![](./Static/%ED%9B%88%EB%A0%A8%EB%8D%B0%EC%9D%B4%ED%84%B0.png)\n",
    "\n",
    "독립 변수 x의 개수가 3개이므로 이를 수식으로 표현하면 아래와 같습니다.  \n",
    "H(x) = w_{1}x_{1} + w_{2}x_{2} + w_{3}x_{3} + b"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 파이토치로 구현하기\n",
    "우선 필요한 도구들을 임포트하고 랜덤 시드를 고정합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x19083a9e450>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 훈련 데이터를 선언해보겠습니다.\n",
    "H(x) = w_{1}x_{1} + w_{2}x_{2} + w_{3}x_{3} + b\n",
    "\n",
    "위의 식을 보면 이번에는 단순 선형 회귀와 다르게 x의 개수가 3개입니다. 그리니까 x를 3개 선언합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련 데이터\n",
    "x1_train = torch.FloatTensor([[73], [93], [89], [96], [73]])\n",
    "x2_train = torch.FloatTensor([[80], [88], [91], [98], [66]])\n",
    "x3_train = torch.FloatTensor([[75], [93], [90], [100], [70]])\n",
    "y_train = torch.FloatTensor([[152], [185], [180], [196], [142]])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 가중치 w와 편향 b를 선언합니다. 가중치 w도 3개 선언해주어야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 가중치 w와 편향 b 초기화\n",
    "w1 = torch.zeros(1, requires_grad=True)\n",
    "w2 = torch.zeros(1, requires_grad=True)\n",
    "w3 = torch.zeros(1, requires_grad=True)\n",
    "b = torch.zeros(1, requires_grad=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 가설, 비용 함수, 옵티마이저를 선언한 후에 경사 하강법을 1000회 반복합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/1000 w1: 0.294 w2: 0.294 w3: 0.297 b: 0.003 Cost: 29661.800781\n",
      "Epoch  100/1000 w1: 0.674 w2: 0.661 w3: 0.676 b: 0.008 Cost: 1.563634\n",
      "Epoch  200/1000 w1: 0.679 w2: 0.655 w3: 0.677 b: 0.008 Cost: 1.497607\n",
      "Epoch  300/1000 w1: 0.684 w2: 0.649 w3: 0.677 b: 0.008 Cost: 1.435026\n",
      "Epoch  400/1000 w1: 0.689 w2: 0.643 w3: 0.678 b: 0.008 Cost: 1.375730\n",
      "Epoch  500/1000 w1: 0.694 w2: 0.638 w3: 0.678 b: 0.009 Cost: 1.319511\n",
      "Epoch  600/1000 w1: 0.699 w2: 0.633 w3: 0.679 b: 0.009 Cost: 1.266222\n",
      "Epoch  700/1000 w1: 0.704 w2: 0.627 w3: 0.679 b: 0.009 Cost: 1.215696\n",
      "Epoch  800/1000 w1: 0.709 w2: 0.622 w3: 0.679 b: 0.009 Cost: 1.167818\n",
      "Epoch  900/1000 w1: 0.713 w2: 0.617 w3: 0.680 b: 0.009 Cost: 1.122429\n",
      "Epoch 1000/1000 w1: 0.718 w2: 0.613 w3: 0.680 b: 0.009 Cost: 1.079378\n"
     ]
    }
   ],
   "source": [
    "# optimizer 설정\n",
    "optimizer = optim.SGD([w1,w2,w3,b], lr=1e-5)\n",
    "\n",
    "num_epochs = 1000\n",
    "for epoch in range(num_epochs + 1):\n",
    "    \n",
    "    # H(x) 계산\n",
    "    hypothesis = x1_train * w1 + x2_train * w2 + x3_train * w3 + b\n",
    "    \n",
    "    # cost 계산\n",
    "    cost = torch.mean((hypothesis - y_train) ** 2)\n",
    "    \n",
    "    # cost로 H(x) 개선\n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    # 100번마다 로그 출력\n",
    "    if epoch % 100 == 0:\n",
    "        print('Epoch {:4d}/{} w1: {:.3f} w2: {:.3f} w3: {:.3f} b: {:.3f} Cost: {:.6f}'.format(\n",
    "            epoch, num_epochs, w1.item(), w2.item(), w3.item(), b.item(), cost.item()\n",
    "        ))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위의 경우 가설을 선언하는 부분인 hypothesis = x1_train * w1 + x2_train * w2 + x3_train * w3 + b에서도 x_train의 개수만큼 w와 곱해주도록 작성해준 것을 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9cc4cb84d376c55cbcefbb2577a30e93afba84ecdcb02495984b572f007c87af"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
