{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 합성곱 신경망을 활용한 큐-함수\n",
    "\n",
    "딥 큐-러닝은 큐 값의 정확도를 높이려고 합성곱 신경망을 도입했습니다.\n",
    "\n",
    "이제 딥 큐-러닝(DQN)을 예제로 살펴보겠습니다.\n",
    "\n",
    "이번에 진행할 예제에서는 OpenAI Gym의 CartPole-v1을 이용합니다. CartPole-v1의 에이전트는 카트에 부착된 막대기가 수직 상태를 유지할 수 있도록 카트를 왼쪽 또는 오른쪽으로 이동하는 작업을 반복합니다. 즉, 중심을 찾기 위해 지속적으로 이동하는 과정을 반복합니다.\n",
    "\n",
    "![](../pytorch_wikidocs/Static/660.jpg)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "에이전트가 환경의 현재 상태를 관찰하고 카트를 오른쪽 혹은 왼쪽으로 이동하면 환경은 새로운 상태로 전이되고 행동(왼쪽 혹은 오른쪽 이동)의 결과로 보상을 받게 됩니다. 보상은 +1이 주어집니다. 막대기가 중심에서 너무 멀리 떨어지거나 카트가 중심에서 멀어지면 게임은 종료됩니다. 즉, 게임이 오래 지속될수록 더 많은 보상을 받을 수 있습니다.\n",
    "\n",
    "예제를 실행하기 위해 다음 패키지를 설치합니다.\n",
    "pip install gym\n",
    "\n",
    "`gym`은 손쉽게 강화 학습 환경을 구성할 수 있도록 도와주는 파이썬 패키지입니다. \n",
    "\n",
    "예제는 파이토치 튜토리얼에서 제공하는 코드를 조금 수정한 것입니다. 튜토리얼의 코드와 비교하면서 살펴보거나 직접 조금씩 변경하여 학습하면 빠르게 실력을 향상시킬 수 있습니다.\n",
    "먼저 필요한 라이브러리를 호출합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from collections import namedtuple # 튜플에 담긴 요소들의 인덱스와 값으로 모두 접근 가능\n",
    "from itertools import count # 무한 루프 사용을 위한 라이브러리\n",
    "from PIL import Image # 이미지 처리를 위한 라이브러리\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# cartpole 이라는 강화 학습 환경을 불러옵니다.\n",
    "env = gym.make('CartPole-v1', render_mode='rgb_array').unwrapped\n",
    "plt.ion()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다음은 출력 결과에서 한글이 깨지는 현상을 방지하기 위한 코드를 작성합니다. 경로 변경 없이 그대로 사용해야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import font_manager\n",
    "font_fname = 'C:/Windows/Fonts/malgun.ttf'\n",
    "font_family = font_manager.FontProperties(fname=font_fname).get_name()\n",
    "plt.rcParams[\"font.family\"] = font_family"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DQN은 리플레이 메모리를 사용합니다. 리플레이 메모리에 에이전트가 관찰한 `상태 전이(state transition)`, `상태`, `행동` 등을 저장하여 나중에 재사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "Transition = namedtuple('Transition',('state','action','next_state','reward'))\n",
    "\n",
    "class ReplayMemory(object):\n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity\n",
    "        self.memory = []\n",
    "        self.position = 0\n",
    "\n",
    "    def push(self, *args):\n",
    "        if len(self.memory) < self.capacity:\n",
    "            self.memory.append(None)\n",
    "        self.memory[self.position] = Transition(*args)\n",
    "        self.position = (self.position + 1) % self.capacity\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, batch_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)\n",
    "\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `Transition = namedtuple('Transition',('state','action','next_state','reward'))` \n",
    "\n",
    "    `namedtuple`에는 상태 전이와 관련된 정보들을 포함합니다. 현재의 상태와 행동(state, action)은 다음 상태와 보상(next_state, reward)로 매핑됩니다. 즉, 현재의 상태에 대해 행동을 하게 되면 그것에 대한 보상이 주어지고 다음 상태를 보여 주기 때문에 현재 상태, 행동, 다음 상태, 보상에 대한 정보들을 관리합니다.\n",
    "\n",
    "* `class ReplayMemory(object)`\n",
    "\n",
    "    `리플레이 메모리(버퍼)` 에는 최근에 관찰된 전이(transition), 현재 상태, 행동, 다음 상태, 보상 정보들이 담기게 됩니다. 또한, `.sample()` 메서드는 리플레이 메모리에 저장된 데이터 중 랜덤하게 배치 크기(batch_size)만큼 반환합니다.\n",
    "\n",
    "    Cartpole 에제는 통제된 상황(에이전트의 모든 행동이 예측 가능한 상황)을 가정합니다. 하지만 현실에서는 완벽하게 통제된 상황은 존재하지 않습니다. 따라서 DQN 신경망을 이용하여 Q(action - value) 함수와 유사하도록 네트워크를 생성합니다. 또한, 모델 학습의 목표는 누적보상이 최대가 되는 것입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DQN 모델 네트워크\n",
    "\n",
    "class DQN(nn.Module):\n",
    "    def __init__(self, h, w, outputs):\n",
    "        super(DQN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=5, stride=2)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=5, stride=2)\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "        self.conv3 = nn.Conv2d(32, 32, kernel_size=5, stride=2)\n",
    "        self.bn3 = nn.BatchNorm2d(32)\n",
    "\n",
    "        def conv2d_size_out(size, kernel_size = 5, stride = 2):\n",
    "            return (size - (kernel_size -1) -1) // stride + 1\n",
    "\n",
    "        convw = conv2d_size_out(conv2d_size_out(conv2d_size_out(w)))\n",
    "        convh = conv2d_size_out(conv2d_size_out(conv2d_size_out(h)))\n",
    "        linear_input_size = convw * convh * 32\n",
    "        self.head = nn.Linear(linear_input_size, outputs)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        return self.head(x.view(x.size(0), -1)) # 함수의 반환값은 다음 행동을 결정하기 위해 사용\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 선형 계층의 입력은 `합성곱층(conv2d)`의 출력과 입력 이미지의 크기에 따라 달라지므로 `convw * convh * 32` 와 같이 계산해야 합니다.\n",
    "\n",
    "이제 환경에서 이미지를 추출하고 처리하는 함수를 정의합니다. 이때 다양한 이미지 변환을 쉽게 처리할 수 있도록 torchvision 패키지를 사용합니다.\n",
    "\n",
    "먼저 pyglet 패키지를 설치합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aqs45\\AppData\\Local\\Temp\\ipykernel_576\\2076529346.py:7: DeprecationWarning: CUBIC is deprecated and will be removed in Pillow 10 (2023-07-01). Use BICUBIC or Resampling.BICUBIC instead.\n",
      "  transforms.Resize(40, interpolation=Image.CUBIC),\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pyglet\n",
    "import torchvision\n",
    "import numpy as np\n",
    "\n",
    "resize = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize(40, interpolation=Image.CUBIC),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "def get_cart_location(screen_width): #카트의 위치 정보 가져오기\n",
    "    world_width = env.x_threshold * 2\n",
    "    scale = screen_width / world_width\n",
    "    return int(env.state[0] * scale + screen_width / 2.0) # 카트의 중앙위치\n",
    "\n",
    "def get_screen():\n",
    "    screen = env.render().transpose((2, 0, 1))\n",
    "    _, screen_height, screen_width = screen.shape\n",
    "    screen = screen[:, int(screen_height * 0.4):int(screen_height * 0.8)]\n",
    "    view_width = int(screen_width * 0.6)\n",
    "    cart_location = get_cart_location(screen_width=screen_width)\n",
    "\n",
    "    if cart_location < view_width // 2: # 카트는 출력 화면의 아래쪽 중앙에 존재하므로 화면의 위쪽과 아래쪽을 제거\n",
    "        slice_range = slice(view_width)\n",
    "    \n",
    "    elif cart_location > (screen_width - view_width // 2):\n",
    "        slice_range = slice(-view_width, None)\n",
    "    \n",
    "    else:\n",
    "        slice_range = slice(cart_location - view_width // 2, cart_location + view_width // 2)\n",
    "    \n",
    "    screen = screen[:, :, slice_range] # 카트가 화면의 중앙에 위치하도록 가장자리를 제거\n",
    "    screen = np.ascontiguousarray(screen, dtype=np.float32) / 255\n",
    "    screen = torch.from_numpy(screen) # 텐서로 변환\n",
    "    return resize(screen).unsqueeze(0).to(device=device)\n",
    "\n",
    "env.reset() # 환경을 초기화\n",
    "plt.figure()\n",
    "plt.imshow(get_screen().cpu().squeeze(0).permute(1, 2, 0).numpy(),interpolation='none')  # permute 함수는 transpose 함수처럼 차원을 바꾸어서 표현할 때 사용\n",
    "plt.title('화면 예시')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "GAMMA = 0.999\n",
    "EPS_START = 0.9\n",
    "EPS_END = 0.05\n",
    "EPS_DECAY = 200\n",
    "TARGET_UPDATE = 10\n",
    "init_screen = get_screen()\n",
    "_, _, screen_height, screen_width = init_screen.shape\n",
    "n_actions = env.action_space.n\n",
    "\n",
    "policy_net = DQN(screen_height, screen_width, n_actions).to(device)\n",
    "target_net = DQN(screen_height, screen_width, n_actions).to(device)\n",
    "target_net.load_state_dict(policy_net.state_dict())\n",
    "target_net.eval()\n",
    "\n",
    "optimizer = optim.RMSprop(policy_net.parameters())\n",
    "memory = ReplayMemory(10000)\n",
    "\n",
    "steps_done = 0\n",
    "\n",
    "\n",
    "def select_action(state):\n",
    "    global steps_done\n",
    "    sample = random.random()\n",
    "    eps_threshold = EPS_END + (EPS_START - EPS_END) * \\\n",
    "        math.exp(-1. * steps_done / EPS_DECAY)\n",
    "    steps_done += 1\n",
    "    if sample > eps_threshold:\n",
    "        with torch.no_grad():\n",
    "            return policy_net(state).max(1)[1].view(1, 1)\n",
    "    else:\n",
    "        return torch.tensor([[random.randrange(n_actions)]], device=device,  dtype=torch.long)\n",
    "\n",
    "\n",
    "episode_durations = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_model():\n",
    "    if len(memory) < BATCH_SIZE:\n",
    "        return\n",
    "\n",
    "    transitions = memory.sample(BATCH_SIZE)\n",
    "    batch = Transition(*zip(*transitions))\n",
    "    non_final_mask = torch.tensor(tuple(map(lambda s: s is not None, batch.next_state)), device=device, dtype=torch.bool) \n",
    "    non_final_next_states = torch.cat([s for s in batch.next_state if s is not None])\n",
    "\n",
    "    state_batch = torch.cat(batch.state)\n",
    "    action_batch = torch.cat(batch.action)\n",
    "    reward_batch = torch.cat(batch.reward)\n",
    "\n",
    "    state_action_values = policy_net(state_batch).gather(1, action_batch)\n",
    "    next_state_values = torch.zeros(BATCH_SIZE, device=device)\n",
    "    next_state_values[non_final_mask] = target_net(non_final_next_states).max(1)[0].detach()\n",
    "\n",
    "    expected_state_action_values = (next_state_values * GAMMA) + reward_batch \n",
    "\n",
    "    loss = F.smooth_l1_loss(state_action_values, expected_state_action_values.unsqueeze(1))\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "\n",
    "    for param in policy_net.parameters():\n",
    "        param.grad.data.clamp_(-1, 1)\n",
    "    optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "종료\n"
     ]
    }
   ],
   "source": [
    "num_episodes = 50\n",
    "\n",
    "for i_episode in range(num_episodes):\n",
    "    env.reset()\n",
    "    last_screen = get_screen()\n",
    "    current_screen = get_screen()\n",
    "    state = current_screen - last_screen\n",
    "\n",
    "    for t in count():\n",
    "        action = select_action(state)\n",
    "        _, reward, done, _, _ = env.step(action.item())\n",
    "        reward = torch.tensor([reward], device=device)\n",
    "\n",
    "        last_screen = current_screen\n",
    "        current_screen = get_screen()\n",
    "\n",
    "        if not done:\n",
    "            next_state = current_screen - last_screen\n",
    "        else:\n",
    "            next_state = None\n",
    "\n",
    "        memory.push(state, action, next_state, reward)\n",
    "        state = next_state\n",
    "\n",
    "        optimize_model()\n",
    "        if done:\n",
    "            episode_durations.append(t + 1)\n",
    "            break\n",
    "\n",
    "    if i_episode % TARGET_UPDATE == 0:\n",
    "        target_net.load_state_dict(policy_net.state_dict())\n",
    "\n",
    "print('종료')\n",
    "env.render()\n",
    "env.close()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\aqs45\\OneDrive\\바탕 화면\\repo\\Python_AI\\venv\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'11.6'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.version.cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch version:1.13.1+cu116\n",
      "cuda version: 11.6\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"Torch version:{}\".format(torch.__version__))\n",
    "print(\"cuda version: {}\".format(torch.version.cuda))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "969136afa1ab1e40cee0417c89a6b891bc5152d071e81b6238bc15b76e770f08"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
