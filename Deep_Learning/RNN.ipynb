{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN(Recurrent Neural Network, 순환 신경망)\n",
    "* 개념 소개\n",
    "    * 일반적인 신경망을 FFNN이라고 하는데 FFNN은 데이터를 입력하면 입력층에서 은닉층까지 연산이 순차적으로 진행되고 출력으로 나가게 된다. 이 과정에서 입력 데이터는 모든 노드를 딱 한 번씩만 지나가게 되며 데이터의 순서 즉 시간적인 측면을 고려하지 않는 구조다. 데이터들의 시간 순서를 무시하고 현재 주어진 데이터를 통해서 독립적으로 학습을 한다.\n",
    "    * RNN은 은닉층의 결과가 다시 같은 은닉층의 입력으로 들어가도록 연결되어 있다.\n",
    "    * RNN이 순서 또는 시간이라는 측면을 고려할 수 있는 특징을 가진다.\n",
    "    * RNN에서 Recurrnet는 반복되는,되풀이되는 이라는 의미를 가지고 있는데 이 이름은 은닉층의 결과가 다시 은닉층으로 들어가게 되는 특성에서 나왔다.\n",
    "    * 개별 데이터를 독립적으로 학습하는 FFNN의 경우는 Sequence data를 처리하는데 어려움이 있지만 RNN은 Sequence data를 다루는데 유용하다.\n",
    "    * 대표적인 형태로는 '문장'과 같은 데이터가 있다. 문장의 단어 같은 경우 현재의 단어만으로 의미를 해석하는 것이 아니라 앞 단어와의 관계를 통해서 현재 단어의 의미를 해석할 수 있다.\n",
    "    * 이외에도 유전자, 손글씨, 음성 신호, 센서가 감지한 데이터, 주가 등의 배열(squence, 또는 시계열 데이터)를 처리하는데 자주 활용될 수 있다.\n",
    "\n",
    "* 순환 신경망 구조\n",
    "    * RNN은 은닉층의 노드에서 활성화 함수를 통해 나온 결과값을 출력층 방향으로도 보내면서, 다시 은닉층 노드의 다음 계산의 입력으로 보내는 특징을 가지고 있다.\n",
    "    * 은닉층의 메모리 셀은 각각의 시점(Time step)에서 바로 이전 시점에서의 은닉층의 메모리셀에서 나온 값을 자신의 입력으로 사용하는 재귀적 활동을 한다.\n",
    "    * 메모리 셀이 출력층 방향으로 또는 다음 시점 t+1의 자신에게 보내는 값을 은닉 상태(hidden state)라고 한다. t 시점의 메모리 셀은 t-1 시점의 메모리 셀이 보낸 은닉 상태값을 t 시점의 은닉 상태 계산을 위한 입력값으로 사용한다.\n",
    "    * RNN은 입력과 출력의 길이를 다르게 설계 할 수 있으므로 다양한 용도로 사용할 수 있다.\n",
    "    * 일대다는 하나의 입력에 대해서 여러개의 출력의 모델을 하나의 이미지 입력에 대해서 사진의 제목을 출력하는 이미지 캡셔닝(Image captioning) 작업에 사용할 수 있다.\n",
    "    * 다대일은 입력 문서가 긍정적인지 부정적인지를 판별하는 감성 분류(sentiment classification), 또는 메일의 정상 메일인지 스팸 메일인지 판별하는 스팸 메일 분류(span detection)에 사용할 수 있다.\n",
    "    * 다대다 모델의 경우에는 입력 문장으로 부터 대답 문장을 출력하는 챗봇과 입력 문장으로부터 번역된 문장을 출력하는 번역기, 또는 개체명 인식이나 품사 태깅과 같은 작업들이 있다.\n",
    "\n",
    "* 순환 신경망 사용\n",
    "    * 케라스로 RNN 층을 추가하는 코드는 다음과 같다\n",
    "         ```py\n",
    "        model.add(SimpleRNN(hidden_size)) # 가장 간단한 형태\n",
    "        ```\n",
    "    * 추가 인자를 사용할 때\n",
    "        ```py\n",
    "        model.add(SimpleRNN(hidden_size, input_length=M, input_dim=N))\n",
    "        ```\n",
    "        - hidden_size : 은닉 상태의 크기를 정의, 메모리 셀이 다음 시점의 메모리 셀과 출력층으로 보내는 값의 크기와 동일, 중소형 모델의 경우 보통 128,256,512,1024 등의 값을 사용\n",
    "        - timesteps : 입력 시퀀스의 길이(input_length)라고 표현하기도 함\n",
    "        - input_dim : 입력의 크기\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn (SimpleRNN)      (None, 3)                 42        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 42\n",
      "Trainable params: 42\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# RNN 층에 대한 코드\n",
    "from keras.models import Sequential\n",
    "from keras.layers import SimpleRNN\n",
    "\n",
    "model = Sequential()\n",
    "model.add(SimpleRNN(3, input_shape=(2,10))) #입력층 노드 10개, 은닉층 노드 3개, 출력층 노드 x,\n",
    "# 10*3(입력층) + 3**2(은닉층) + 3(출력층) = 42\n",
    "#model.add(SimpleRNN(3, input_length=2, input_dim = 10)) 이렇게 실행해도 결과는 같음\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn_1 (SimpleRNN)    (8, 3)                    42        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 42\n",
      "Trainable params: 42\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import SimpleRNN\n",
    "model = Sequential()\n",
    "model.add(SimpleRNN(3, batch_input_shape=(8,2,10))) # return_sequences=False 인 경우\n",
    "#batch_input_shape(batch사이즈, timesteps, input_dim(입력데이터의 크기))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn_2 (SimpleRNN)    (8, 2, 3)                 42        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 42\n",
      "Trainable params: 42\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import SimpleRNN\n",
    "model = Sequential()\n",
    "model.add(SimpleRNN(3, batch_input_shape=(8,2,10), return_sequences=True)) # return_sequences=True 인 경우\n",
    "#batch_input_shape(batch사이즈, timesteps, input_dim(입력데이터의 크기))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM(Long Short-Term Memory, 장단기 메모리)\n",
    "* 개념 소개\n",
    "    * RNN은 출력 결과가 이전의 계산 결과에 의존하기 때문에 RNN의 시점(Time step)이 길어질수록 앞의 정보가 뒤로 충분히 전달되지 못하는 현상이 발생한다.\n",
    "    * 첫번째 입력값인 x1의 정보량을 짙은 남색으로 표현했을 때, 색이 점차 얕아지는 것으로 시점이 지날수록 x1의 정보량이 손실되어가는 과정을 표현하였다. 뒤로 갈수록 x1의 정보량은 손실되고 x1의 전체 정보에 대한 영향력은 거의 의미가 없을 수도 있다.\n",
    "    * 가장 중요한 정보가 시점의 앞 쪽에 위치할 수도 있다. RNN으로 만든 언어 모델이 다음 단어를 예측하는 과정을 생각해보자. 예를 들어 '모스크바에 여행을 왔는데 건물도 에쁘고 먹을 것도 맛있었어. 그런데 직장 상사한테 전화가 왔어. 어디냐고 묻더라구 그래서 나는 말했지. 저 여행왔는데요 여기___ ' 다음 단어를 예측하기 위해서는 장소 정보가 필요한데 장소 정보에 해당되는 단어인 '모스크바'는 앞에 위치하고 있고, RNN이 충분한 기억력을 가지고 있지 못한다면 다음 단어를 엉뚱하게 예측한다.\n",
    "    * 이를 장기 의존성 문제 (the problem of long-term dependencies)라고 한다.\n",
    "\n",
    "* LSTM\n",
    "    * 전통적인 RNN의 이러한 단점을 보완한 RNN의 일종을 장단기 메모리(LSTM)라고 한다. LSTM은 은닉층의 메모리 셀에 입력 게이트, 망각 게이트, 출력 게이트를 추가하여 불필요한 기억을 지우고, 기억해야할 것들을 정한다.\n",
    "    * 셀 상태\n",
    "        - 셀 상태 은닉 상태처럼 이전 시점의 셀상태가 다음 시점의 셀 상태를 궇기 위한 입력으로서 사용된다.\n",
    "        - 은닉 상태값과 셀 상태값을 구하기 위해서 새로 추가 된 3개의 게이트를 사용한다. 각 게이트는 삭제게이트, 입력 게이트, 출력 게이트라고 부르며 이 3개의 게이트에는 공통적으로 시그모이드 함수가 존재한다. 시그모이드 함수를 지나면 0과 1사이의 값이 나오게 되는데 이 값들을 가지고 게이트를 조절한다.\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합의 크기:12\n",
      "{'말이': 1, '경마장에': 2, '있는': 3, '뛰고': 4, '있다': 5, '그의': 6, '법이다': 7, '가는': 8, '고와야': 9, '오는': 10, '곱다': 11}\n"
     ]
    }
   ],
   "source": [
    "# RNN을 이용하여 텍스트 생성하기\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "text=\"\"\"경마장에 있는 말이 뛰고 있다\\n 그의 말이 법이다\\n 가는 말이 고와야 오는 말이 곱다\\n\"\"\"\n",
    "t = Tokenizer()\n",
    "t.fit_on_texts([text])\n",
    "vocab_size = len(t.word_index) + 1\n",
    "print('단어 집합의 크기:%d' % vocab_size)\n",
    "print(t.word_index) # 각 단어와 단어에 부여된 정수 인덱스 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습에 사용할 샘플의 개수: 11\n",
      "[[2, 3], [2, 3, 1], [2, 3, 1, 4], [2, 3, 1, 4, 5], [6, 1], [6, 1, 7], [8, 1], [8, 1, 9], [8, 1, 9, 10], [8, 1, 9, 10, 1], [8, 1, 9, 10, 1, 11]]\n"
     ]
    }
   ],
   "source": [
    "sequences = list()\n",
    "for line in text.split('\\n'): #\\n을 기준으로 문장 토큰화\n",
    "    encoded = t.texts_to_sequences([line])[0]\n",
    "    for i in range(1, len(encoded)):\n",
    "        sequence = encoded[:i+1]\n",
    "        sequences.append(sequence)\n",
    "print('학습에 사용할 샘플의 개수: %d' % len(sequences))\n",
    "print(sequences) #전체 샘플을 출력\n",
    "\n",
    "# 위의 데이터는 아직 레이블로 사용될 단어를 분리하지 않은 훈련 데이터이다. [2,3]은 [경마장에,있는]에 해당되며 [2,3,1]은\n",
    "# [경마장에, 있는, 말이]에 해당된다. 전체 훈련 데이터에 대해서 맨 우측에 있는 단어에 대해서만 레이블로 분리해야 한다.\n",
    "# 우선 전체 샘플에 대해서 길이를 일치시켜 준다. 가장 긴 샘플의 길이를 기준으로 한다. 현재 육안으로 봤을 때\n",
    "# 가장 길이가 긴 샘플은 [8,1,9,10,1,11]이고 길이는 6이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "샘플의 최대 길이: 6\n"
     ]
    }
   ],
   "source": [
    "max_len=max(len(I) for I in sequences) #모든 샘플에서 길이가 가장 긴 샘플의 길이 출력\n",
    "print('샘플의 최대 길이: {}'.format(max_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  0  0  0  2  3]\n",
      " [ 0  0  0  2  3  1]\n",
      " [ 0  0  2  3  1  4]\n",
      " [ 0  2  3  1  4  5]\n",
      " [ 0  0  0  0  6  1]\n",
      " [ 0  0  0  6  1  7]\n",
      " [ 0  0  0  0  8  1]\n",
      " [ 0  0  0  8  1  9]\n",
      " [ 0  0  8  1  9 10]\n",
      " [ 0  8  1  9 10  1]\n",
      " [ 8  1  9 10  1 11]]\n"
     ]
    }
   ],
   "source": [
    "#전체 샘플의 길이를 6으로 패딩\n",
    "sequences = pad_sequences(sequences, maxlen=max_len, padding='pre')\n",
    "print(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  0  0  0  2]\n",
      " [ 0  0  0  2  3]\n",
      " [ 0  0  2  3  1]\n",
      " [ 0  2  3  1  4]\n",
      " [ 0  0  0  0  6]\n",
      " [ 0  0  0  6  1]\n",
      " [ 0  0  0  0  8]\n",
      " [ 0  0  0  8  1]\n",
      " [ 0  0  8  1  9]\n",
      " [ 0  8  1  9 10]\n",
      " [ 8  1  9 10  1]]\n",
      "[ 3  1  4  5  1  7  1  9 10  1 11]\n"
     ]
    }
   ],
   "source": [
    "sequences = np.array(sequences)\n",
    "x = sequences[:,:-1] #학습 데이터\n",
    "y = sequences[:,-1] #정답 데이터\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "y = to_categorical(y, num_classes=vocab_size) #원핫 인코딩 수행\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001E9763998B8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001E9763998B8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1/1 - 1s - loss: 2.4905 - accuracy: 0.0909 - 759ms/epoch - 759ms/step\n",
      "Epoch 2/200\n",
      "1/1 - 0s - loss: 2.4790 - accuracy: 0.1818 - 3ms/epoch - 3ms/step\n",
      "Epoch 3/200\n",
      "1/1 - 0s - loss: 2.4677 - accuracy: 0.1818 - 2ms/epoch - 2ms/step\n",
      "Epoch 4/200\n",
      "1/1 - 0s - loss: 2.4565 - accuracy: 0.1818 - 3ms/epoch - 3ms/step\n",
      "Epoch 5/200\n",
      "1/1 - 0s - loss: 2.4453 - accuracy: 0.1818 - 5ms/epoch - 5ms/step\n",
      "Epoch 6/200\n",
      "1/1 - 0s - loss: 2.4338 - accuracy: 0.3636 - 4ms/epoch - 4ms/step\n",
      "Epoch 7/200\n",
      "1/1 - 0s - loss: 2.4221 - accuracy: 0.4545 - 4ms/epoch - 4ms/step\n",
      "Epoch 8/200\n",
      "1/1 - 0s - loss: 2.4100 - accuracy: 0.5455 - 3ms/epoch - 3ms/step\n",
      "Epoch 9/200\n",
      "1/1 - 0s - loss: 2.3974 - accuracy: 0.4545 - 3ms/epoch - 3ms/step\n",
      "Epoch 10/200\n",
      "1/1 - 0s - loss: 2.3842 - accuracy: 0.4545 - 6ms/epoch - 6ms/step\n",
      "Epoch 11/200\n",
      "1/1 - 0s - loss: 2.3702 - accuracy: 0.4545 - 3ms/epoch - 3ms/step\n",
      "Epoch 12/200\n",
      "1/1 - 0s - loss: 2.3553 - accuracy: 0.4545 - 8ms/epoch - 8ms/step\n",
      "Epoch 13/200\n",
      "1/1 - 0s - loss: 2.3394 - accuracy: 0.3636 - 5ms/epoch - 5ms/step\n",
      "Epoch 14/200\n",
      "1/1 - 0s - loss: 2.3225 - accuracy: 0.3636 - 4ms/epoch - 4ms/step\n",
      "Epoch 15/200\n",
      "1/1 - 0s - loss: 2.3045 - accuracy: 0.3636 - 3ms/epoch - 3ms/step\n",
      "Epoch 16/200\n",
      "1/1 - 0s - loss: 2.2852 - accuracy: 0.3636 - 2ms/epoch - 2ms/step\n",
      "Epoch 17/200\n",
      "1/1 - 0s - loss: 2.2646 - accuracy: 0.3636 - 3ms/epoch - 3ms/step\n",
      "Epoch 18/200\n",
      "1/1 - 0s - loss: 2.2428 - accuracy: 0.3636 - 3ms/epoch - 3ms/step\n",
      "Epoch 19/200\n",
      "1/1 - 0s - loss: 2.2196 - accuracy: 0.3636 - 2ms/epoch - 2ms/step\n",
      "Epoch 20/200\n",
      "1/1 - 0s - loss: 2.1951 - accuracy: 0.3636 - 2ms/epoch - 2ms/step\n",
      "Epoch 21/200\n",
      "1/1 - 0s - loss: 2.1694 - accuracy: 0.3636 - 5ms/epoch - 5ms/step\n",
      "Epoch 22/200\n",
      "1/1 - 0s - loss: 2.1427 - accuracy: 0.3636 - 2ms/epoch - 2ms/step\n",
      "Epoch 23/200\n",
      "1/1 - 0s - loss: 2.1152 - accuracy: 0.3636 - 3ms/epoch - 3ms/step\n",
      "Epoch 24/200\n",
      "1/1 - 0s - loss: 2.0870 - accuracy: 0.3636 - 4ms/epoch - 4ms/step\n",
      "Epoch 25/200\n",
      "1/1 - 0s - loss: 2.0587 - accuracy: 0.3636 - 2ms/epoch - 2ms/step\n",
      "Epoch 26/200\n",
      "1/1 - 0s - loss: 2.0307 - accuracy: 0.3636 - 3ms/epoch - 3ms/step\n",
      "Epoch 27/200\n",
      "1/1 - 0s - loss: 2.0034 - accuracy: 0.3636 - 4ms/epoch - 4ms/step\n",
      "Epoch 28/200\n",
      "1/1 - 0s - loss: 1.9773 - accuracy: 0.3636 - 2ms/epoch - 2ms/step\n",
      "Epoch 29/200\n",
      "1/1 - 0s - loss: 1.9529 - accuracy: 0.3636 - 2ms/epoch - 2ms/step\n",
      "Epoch 30/200\n",
      "1/1 - 0s - loss: 1.9304 - accuracy: 0.3636 - 2ms/epoch - 2ms/step\n",
      "Epoch 31/200\n",
      "1/1 - 0s - loss: 1.9099 - accuracy: 0.3636 - 5ms/epoch - 5ms/step\n",
      "Epoch 32/200\n",
      "1/1 - 0s - loss: 1.8914 - accuracy: 0.3636 - 3ms/epoch - 3ms/step\n",
      "Epoch 33/200\n",
      "1/1 - 0s - loss: 1.8742 - accuracy: 0.3636 - 2ms/epoch - 2ms/step\n",
      "Epoch 34/200\n",
      "1/1 - 0s - loss: 1.8579 - accuracy: 0.3636 - 4ms/epoch - 4ms/step\n",
      "Epoch 35/200\n",
      "1/1 - 0s - loss: 1.8419 - accuracy: 0.3636 - 3ms/epoch - 3ms/step\n",
      "Epoch 36/200\n",
      "1/1 - 0s - loss: 1.8255 - accuracy: 0.3636 - 2ms/epoch - 2ms/step\n",
      "Epoch 37/200\n",
      "1/1 - 0s - loss: 1.8085 - accuracy: 0.3636 - 2ms/epoch - 2ms/step\n",
      "Epoch 38/200\n",
      "1/1 - 0s - loss: 1.7906 - accuracy: 0.3636 - 5ms/epoch - 5ms/step\n",
      "Epoch 39/200\n",
      "1/1 - 0s - loss: 1.7720 - accuracy: 0.3636 - 2ms/epoch - 2ms/step\n",
      "Epoch 40/200\n",
      "1/1 - 0s - loss: 1.7528 - accuracy: 0.3636 - 3ms/epoch - 3ms/step\n",
      "Epoch 41/200\n",
      "1/1 - 0s - loss: 1.7333 - accuracy: 0.3636 - 4ms/epoch - 4ms/step\n",
      "Epoch 42/200\n",
      "1/1 - 0s - loss: 1.7138 - accuracy: 0.3636 - 2ms/epoch - 2ms/step\n",
      "Epoch 43/200\n",
      "1/1 - 0s - loss: 1.6944 - accuracy: 0.3636 - 2ms/epoch - 2ms/step\n",
      "Epoch 44/200\n",
      "1/1 - 0s - loss: 1.6754 - accuracy: 0.3636 - 3ms/epoch - 3ms/step\n",
      "Epoch 45/200\n",
      "1/1 - 0s - loss: 1.6566 - accuracy: 0.4545 - 3ms/epoch - 3ms/step\n",
      "Epoch 46/200\n",
      "1/1 - 0s - loss: 1.6381 - accuracy: 0.4545 - 3ms/epoch - 3ms/step\n",
      "Epoch 47/200\n",
      "1/1 - 0s - loss: 1.6197 - accuracy: 0.4545 - 2ms/epoch - 2ms/step\n",
      "Epoch 48/200\n",
      "1/1 - 0s - loss: 1.6012 - accuracy: 0.5455 - 3ms/epoch - 3ms/step\n",
      "Epoch 49/200\n",
      "1/1 - 0s - loss: 1.5824 - accuracy: 0.5455 - 3ms/epoch - 3ms/step\n",
      "Epoch 50/200\n",
      "1/1 - 0s - loss: 1.5632 - accuracy: 0.5455 - 2ms/epoch - 2ms/step\n",
      "Epoch 51/200\n",
      "1/1 - 0s - loss: 1.5436 - accuracy: 0.5455 - 3ms/epoch - 3ms/step\n",
      "Epoch 52/200\n",
      "1/1 - 0s - loss: 1.5234 - accuracy: 0.5455 - 3ms/epoch - 3ms/step\n",
      "Epoch 53/200\n",
      "1/1 - 0s - loss: 1.5028 - accuracy: 0.5455 - 2ms/epoch - 2ms/step\n",
      "Epoch 54/200\n",
      "1/1 - 0s - loss: 1.4819 - accuracy: 0.5455 - 3ms/epoch - 3ms/step\n",
      "Epoch 55/200\n",
      "1/1 - 0s - loss: 1.4606 - accuracy: 0.5455 - 6ms/epoch - 6ms/step\n",
      "Epoch 56/200\n",
      "1/1 - 0s - loss: 1.4392 - accuracy: 0.5455 - 3ms/epoch - 3ms/step\n",
      "Epoch 57/200\n",
      "1/1 - 0s - loss: 1.4177 - accuracy: 0.5455 - 3ms/epoch - 3ms/step\n",
      "Epoch 58/200\n",
      "1/1 - 0s - loss: 1.3962 - accuracy: 0.5455 - 3ms/epoch - 3ms/step\n",
      "Epoch 59/200\n",
      "1/1 - 0s - loss: 1.3749 - accuracy: 0.5455 - 2ms/epoch - 2ms/step\n",
      "Epoch 60/200\n",
      "1/1 - 0s - loss: 1.3537 - accuracy: 0.5455 - 2ms/epoch - 2ms/step\n",
      "Epoch 61/200\n",
      "1/1 - 0s - loss: 1.3327 - accuracy: 0.5455 - 3ms/epoch - 3ms/step\n",
      "Epoch 62/200\n",
      "1/1 - 0s - loss: 1.3120 - accuracy: 0.5455 - 5ms/epoch - 5ms/step\n",
      "Epoch 63/200\n",
      "1/1 - 0s - loss: 1.2914 - accuracy: 0.6364 - 3ms/epoch - 3ms/step\n",
      "Epoch 64/200\n",
      "1/1 - 0s - loss: 1.2711 - accuracy: 0.6364 - 3ms/epoch - 3ms/step\n",
      "Epoch 65/200\n",
      "1/1 - 0s - loss: 1.2510 - accuracy: 0.6364 - 5ms/epoch - 5ms/step\n",
      "Epoch 66/200\n",
      "1/1 - 0s - loss: 1.2312 - accuracy: 0.6364 - 2ms/epoch - 2ms/step\n",
      "Epoch 67/200\n",
      "1/1 - 0s - loss: 1.2116 - accuracy: 0.6364 - 2ms/epoch - 2ms/step\n",
      "Epoch 68/200\n",
      "1/1 - 0s - loss: 1.1925 - accuracy: 0.6364 - 5ms/epoch - 5ms/step\n",
      "Epoch 69/200\n",
      "1/1 - 0s - loss: 1.1737 - accuracy: 0.6364 - 2ms/epoch - 2ms/step\n",
      "Epoch 70/200\n",
      "1/1 - 0s - loss: 1.1552 - accuracy: 0.6364 - 2ms/epoch - 2ms/step\n",
      "Epoch 71/200\n",
      "1/1 - 0s - loss: 1.1372 - accuracy: 0.6364 - 3ms/epoch - 3ms/step\n",
      "Epoch 72/200\n",
      "1/1 - 0s - loss: 1.1195 - accuracy: 0.6364 - 4ms/epoch - 4ms/step\n",
      "Epoch 73/200\n",
      "1/1 - 0s - loss: 1.1022 - accuracy: 0.6364 - 3ms/epoch - 3ms/step\n",
      "Epoch 74/200\n",
      "1/1 - 0s - loss: 1.0852 - accuracy: 0.6364 - 3ms/epoch - 3ms/step\n",
      "Epoch 75/200\n",
      "1/1 - 0s - loss: 1.0686 - accuracy: 0.6364 - 4ms/epoch - 4ms/step\n",
      "Epoch 76/200\n",
      "1/1 - 0s - loss: 1.0522 - accuracy: 0.6364 - 2ms/epoch - 2ms/step\n",
      "Epoch 77/200\n",
      "1/1 - 0s - loss: 1.0362 - accuracy: 0.7273 - 2ms/epoch - 2ms/step\n",
      "Epoch 78/200\n",
      "1/1 - 0s - loss: 1.0205 - accuracy: 0.7273 - 4ms/epoch - 4ms/step\n",
      "Epoch 79/200\n",
      "1/1 - 0s - loss: 1.0050 - accuracy: 0.7273 - 2ms/epoch - 2ms/step\n",
      "Epoch 80/200\n",
      "1/1 - 0s - loss: 0.9898 - accuracy: 0.7273 - 2ms/epoch - 2ms/step\n",
      "Epoch 81/200\n",
      "1/1 - 0s - loss: 0.9749 - accuracy: 0.7273 - 2ms/epoch - 2ms/step\n",
      "Epoch 82/200\n",
      "1/1 - 0s - loss: 0.9602 - accuracy: 0.7273 - 3ms/epoch - 3ms/step\n",
      "Epoch 83/200\n",
      "1/1 - 0s - loss: 0.9459 - accuracy: 0.7273 - 3ms/epoch - 3ms/step\n",
      "Epoch 84/200\n",
      "1/1 - 0s - loss: 0.9317 - accuracy: 0.7273 - 2ms/epoch - 2ms/step\n",
      "Epoch 85/200\n",
      "1/1 - 0s - loss: 0.9179 - accuracy: 0.7273 - 3ms/epoch - 3ms/step\n",
      "Epoch 86/200\n",
      "1/1 - 0s - loss: 0.9043 - accuracy: 0.7273 - 4ms/epoch - 4ms/step\n",
      "Epoch 87/200\n",
      "1/1 - 0s - loss: 0.8909 - accuracy: 0.7273 - 3ms/epoch - 3ms/step\n",
      "Epoch 88/200\n",
      "1/1 - 0s - loss: 0.8777 - accuracy: 0.7273 - 3ms/epoch - 3ms/step\n",
      "Epoch 89/200\n",
      "1/1 - 0s - loss: 0.8647 - accuracy: 0.7273 - 4ms/epoch - 4ms/step\n",
      "Epoch 90/200\n",
      "1/1 - 0s - loss: 0.8519 - accuracy: 0.7273 - 2ms/epoch - 2ms/step\n",
      "Epoch 91/200\n",
      "1/1 - 0s - loss: 0.8393 - accuracy: 0.7273 - 2ms/epoch - 2ms/step\n",
      "Epoch 92/200\n",
      "1/1 - 0s - loss: 0.8269 - accuracy: 0.7273 - 2ms/epoch - 2ms/step\n",
      "Epoch 93/200\n",
      "1/1 - 0s - loss: 0.8146 - accuracy: 0.7273 - 4ms/epoch - 4ms/step\n",
      "Epoch 94/200\n",
      "1/1 - 0s - loss: 0.8024 - accuracy: 0.7273 - 3ms/epoch - 3ms/step\n",
      "Epoch 95/200\n",
      "1/1 - 0s - loss: 0.7904 - accuracy: 0.7273 - 3ms/epoch - 3ms/step\n",
      "Epoch 96/200\n",
      "1/1 - 0s - loss: 0.7785 - accuracy: 0.7273 - 3ms/epoch - 3ms/step\n",
      "Epoch 97/200\n",
      "1/1 - 0s - loss: 0.7667 - accuracy: 0.7273 - 3ms/epoch - 3ms/step\n",
      "Epoch 98/200\n",
      "1/1 - 0s - loss: 0.7550 - accuracy: 0.7273 - 2ms/epoch - 2ms/step\n",
      "Epoch 99/200\n",
      "1/1 - 0s - loss: 0.7434 - accuracy: 0.7273 - 2ms/epoch - 2ms/step\n",
      "Epoch 100/200\n",
      "1/1 - 0s - loss: 0.7319 - accuracy: 0.7273 - 3ms/epoch - 3ms/step\n",
      "Epoch 101/200\n",
      "1/1 - 0s - loss: 0.7205 - accuracy: 0.7273 - 3ms/epoch - 3ms/step\n",
      "Epoch 102/200\n",
      "1/1 - 0s - loss: 0.7091 - accuracy: 0.8182 - 2ms/epoch - 2ms/step\n",
      "Epoch 103/200\n",
      "1/1 - 0s - loss: 0.6978 - accuracy: 0.8182 - 2ms/epoch - 2ms/step\n",
      "Epoch 104/200\n",
      "1/1 - 0s - loss: 0.6865 - accuracy: 0.8182 - 5ms/epoch - 5ms/step\n",
      "Epoch 105/200\n",
      "1/1 - 0s - loss: 0.6753 - accuracy: 0.8182 - 2ms/epoch - 2ms/step\n",
      "Epoch 106/200\n",
      "1/1 - 0s - loss: 0.6642 - accuracy: 0.8182 - 2ms/epoch - 2ms/step\n",
      "Epoch 107/200\n",
      "1/1 - 0s - loss: 0.6531 - accuracy: 0.8182 - 2ms/epoch - 2ms/step\n",
      "Epoch 108/200\n",
      "1/1 - 0s - loss: 0.6421 - accuracy: 0.8182 - 3ms/epoch - 3ms/step\n",
      "Epoch 109/200\n",
      "1/1 - 0s - loss: 0.6311 - accuracy: 0.8182 - 3ms/epoch - 3ms/step\n",
      "Epoch 110/200\n",
      "1/1 - 0s - loss: 0.6202 - accuracy: 0.8182 - 2ms/epoch - 2ms/step\n",
      "Epoch 111/200\n",
      "1/1 - 0s - loss: 0.6093 - accuracy: 0.8182 - 4ms/epoch - 4ms/step\n",
      "Epoch 112/200\n",
      "1/1 - 0s - loss: 0.5985 - accuracy: 0.8182 - 2ms/epoch - 2ms/step\n",
      "Epoch 113/200\n",
      "1/1 - 0s - loss: 0.5878 - accuracy: 0.8182 - 2ms/epoch - 2ms/step\n",
      "Epoch 114/200\n",
      "1/1 - 0s - loss: 0.5771 - accuracy: 0.8182 - 3ms/epoch - 3ms/step\n",
      "Epoch 115/200\n",
      "1/1 - 0s - loss: 0.5665 - accuracy: 0.8182 - 4ms/epoch - 4ms/step\n",
      "Epoch 116/200\n",
      "1/1 - 0s - loss: 0.5559 - accuracy: 0.8182 - 2ms/epoch - 2ms/step\n",
      "Epoch 117/200\n",
      "1/1 - 0s - loss: 0.5455 - accuracy: 0.8182 - 2ms/epoch - 2ms/step\n",
      "Epoch 118/200\n",
      "1/1 - 0s - loss: 0.5351 - accuracy: 0.8182 - 3ms/epoch - 3ms/step\n",
      "Epoch 119/200\n",
      "1/1 - 0s - loss: 0.5248 - accuracy: 0.9091 - 4ms/epoch - 4ms/step\n",
      "Epoch 120/200\n",
      "1/1 - 0s - loss: 0.5146 - accuracy: 0.9091 - 2ms/epoch - 2ms/step\n",
      "Epoch 121/200\n",
      "1/1 - 0s - loss: 0.5045 - accuracy: 0.9091 - 2ms/epoch - 2ms/step\n",
      "Epoch 122/200\n",
      "1/1 - 0s - loss: 0.4944 - accuracy: 0.9091 - 4ms/epoch - 4ms/step\n",
      "Epoch 123/200\n",
      "1/1 - 0s - loss: 0.4845 - accuracy: 0.9091 - 2ms/epoch - 2ms/step\n",
      "Epoch 124/200\n",
      "1/1 - 0s - loss: 0.4747 - accuracy: 0.9091 - 2ms/epoch - 2ms/step\n",
      "Epoch 125/200\n",
      "1/1 - 0s - loss: 0.4650 - accuracy: 0.9091 - 4ms/epoch - 4ms/step\n",
      "Epoch 126/200\n",
      "1/1 - 0s - loss: 0.4554 - accuracy: 0.9091 - 2ms/epoch - 2ms/step\n",
      "Epoch 127/200\n",
      "1/1 - 0s - loss: 0.4459 - accuracy: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 128/200\n",
      "1/1 - 0s - loss: 0.4365 - accuracy: 1.0000 - 3ms/epoch - 3ms/step\n",
      "Epoch 129/200\n",
      "1/1 - 0s - loss: 0.4272 - accuracy: 1.0000 - 3ms/epoch - 3ms/step\n",
      "Epoch 130/200\n",
      "1/1 - 0s - loss: 0.4181 - accuracy: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 131/200\n",
      "1/1 - 0s - loss: 0.4091 - accuracy: 1.0000 - 3ms/epoch - 3ms/step\n",
      "Epoch 132/200\n",
      "1/1 - 0s - loss: 0.4002 - accuracy: 1.0000 - 4ms/epoch - 4ms/step\n",
      "Epoch 133/200\n",
      "1/1 - 0s - loss: 0.3915 - accuracy: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 134/200\n",
      "1/1 - 0s - loss: 0.3829 - accuracy: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 135/200\n",
      "1/1 - 0s - loss: 0.3744 - accuracy: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 136/200\n",
      "1/1 - 0s - loss: 0.3661 - accuracy: 1.0000 - 5ms/epoch - 5ms/step\n",
      "Epoch 137/200\n",
      "1/1 - 0s - loss: 0.3579 - accuracy: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 138/200\n",
      "1/1 - 0s - loss: 0.3498 - accuracy: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 139/200\n",
      "1/1 - 0s - loss: 0.3419 - accuracy: 1.0000 - 3ms/epoch - 3ms/step\n",
      "Epoch 140/200\n",
      "1/1 - 0s - loss: 0.3341 - accuracy: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 141/200\n",
      "1/1 - 0s - loss: 0.3265 - accuracy: 1.0000 - 3ms/epoch - 3ms/step\n",
      "Epoch 142/200\n",
      "1/1 - 0s - loss: 0.3190 - accuracy: 1.0000 - 3ms/epoch - 3ms/step\n",
      "Epoch 143/200\n",
      "1/1 - 0s - loss: 0.3117 - accuracy: 1.0000 - 3ms/epoch - 3ms/step\n",
      "Epoch 144/200\n",
      "1/1 - 0s - loss: 0.3045 - accuracy: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 145/200\n",
      "1/1 - 0s - loss: 0.2975 - accuracy: 1.0000 - 3ms/epoch - 3ms/step\n",
      "Epoch 146/200\n",
      "1/1 - 0s - loss: 0.2906 - accuracy: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 147/200\n",
      "1/1 - 0s - loss: 0.2838 - accuracy: 1.0000 - 4ms/epoch - 4ms/step\n",
      "Epoch 148/200\n",
      "1/1 - 0s - loss: 0.2772 - accuracy: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 149/200\n",
      "1/1 - 0s - loss: 0.2708 - accuracy: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 150/200\n",
      "1/1 - 0s - loss: 0.2645 - accuracy: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 151/200\n",
      "1/1 - 0s - loss: 0.2583 - accuracy: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 152/200\n",
      "1/1 - 0s - loss: 0.2522 - accuracy: 1.0000 - 3ms/epoch - 3ms/step\n",
      "Epoch 153/200\n",
      "1/1 - 0s - loss: 0.2463 - accuracy: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 154/200\n",
      "1/1 - 0s - loss: 0.2406 - accuracy: 1.0000 - 3ms/epoch - 3ms/step\n",
      "Epoch 155/200\n",
      "1/1 - 0s - loss: 0.2350 - accuracy: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 156/200\n",
      "1/1 - 0s - loss: 0.2295 - accuracy: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 157/200\n",
      "1/1 - 0s - loss: 0.2241 - accuracy: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 158/200\n",
      "1/1 - 0s - loss: 0.2189 - accuracy: 1.0000 - 4ms/epoch - 4ms/step\n",
      "Epoch 159/200\n",
      "1/1 - 0s - loss: 0.2139 - accuracy: 1.0000 - 3ms/epoch - 3ms/step\n",
      "Epoch 160/200\n",
      "1/1 - 0s - loss: 0.2089 - accuracy: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 161/200\n",
      "1/1 - 0s - loss: 0.2041 - accuracy: 1.0000 - 4ms/epoch - 4ms/step\n",
      "Epoch 162/200\n",
      "1/1 - 0s - loss: 0.1994 - accuracy: 1.0000 - 3ms/epoch - 3ms/step\n",
      "Epoch 163/200\n",
      "1/1 - 0s - loss: 0.1948 - accuracy: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 164/200\n",
      "1/1 - 0s - loss: 0.1903 - accuracy: 1.0000 - 3ms/epoch - 3ms/step\n",
      "Epoch 165/200\n",
      "1/1 - 0s - loss: 0.1860 - accuracy: 1.0000 - 5ms/epoch - 5ms/step\n",
      "Epoch 166/200\n",
      "1/1 - 0s - loss: 0.1818 - accuracy: 1.0000 - 3ms/epoch - 3ms/step\n",
      "Epoch 167/200\n",
      "1/1 - 0s - loss: 0.1777 - accuracy: 1.0000 - 3ms/epoch - 3ms/step\n",
      "Epoch 168/200\n",
      "1/1 - 0s - loss: 0.1737 - accuracy: 1.0000 - 5ms/epoch - 5ms/step\n",
      "Epoch 169/200\n",
      "1/1 - 0s - loss: 0.1698 - accuracy: 1.0000 - 3ms/epoch - 3ms/step\n",
      "Epoch 170/200\n",
      "1/1 - 0s - loss: 0.1660 - accuracy: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 171/200\n",
      "1/1 - 0s - loss: 0.1623 - accuracy: 1.0000 - 4ms/epoch - 4ms/step\n",
      "Epoch 172/200\n",
      "1/1 - 0s - loss: 0.1587 - accuracy: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 173/200\n",
      "1/1 - 0s - loss: 0.1553 - accuracy: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 174/200\n",
      "1/1 - 0s - loss: 0.1519 - accuracy: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 175/200\n",
      "1/1 - 0s - loss: 0.1486 - accuracy: 1.0000 - 4ms/epoch - 4ms/step\n",
      "Epoch 176/200\n",
      "1/1 - 0s - loss: 0.1454 - accuracy: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 177/200\n",
      "1/1 - 0s - loss: 0.1423 - accuracy: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 178/200\n",
      "1/1 - 0s - loss: 0.1393 - accuracy: 1.0000 - 4ms/epoch - 4ms/step\n",
      "Epoch 179/200\n",
      "1/1 - 0s - loss: 0.1363 - accuracy: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 180/200\n",
      "1/1 - 0s - loss: 0.1335 - accuracy: 1.0000 - 3ms/epoch - 3ms/step\n",
      "Epoch 181/200\n",
      "1/1 - 0s - loss: 0.1307 - accuracy: 1.0000 - 3ms/epoch - 3ms/step\n",
      "Epoch 182/200\n",
      "1/1 - 0s - loss: 0.1280 - accuracy: 1.0000 - 4ms/epoch - 4ms/step\n",
      "Epoch 183/200\n",
      "1/1 - 0s - loss: 0.1254 - accuracy: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 184/200\n",
      "1/1 - 0s - loss: 0.1229 - accuracy: 1.0000 - 3ms/epoch - 3ms/step\n",
      "Epoch 185/200\n",
      "1/1 - 0s - loss: 0.1204 - accuracy: 1.0000 - 4ms/epoch - 4ms/step\n",
      "Epoch 186/200\n",
      "1/1 - 0s - loss: 0.1180 - accuracy: 1.0000 - 3ms/epoch - 3ms/step\n",
      "Epoch 187/200\n",
      "1/1 - 0s - loss: 0.1156 - accuracy: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 188/200\n",
      "1/1 - 0s - loss: 0.1134 - accuracy: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 189/200\n",
      "1/1 - 0s - loss: 0.1112 - accuracy: 1.0000 - 5ms/epoch - 5ms/step\n",
      "Epoch 190/200\n",
      "1/1 - 0s - loss: 0.1090 - accuracy: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 191/200\n",
      "1/1 - 0s - loss: 0.1069 - accuracy: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 192/200\n",
      "1/1 - 0s - loss: 0.1049 - accuracy: 1.0000 - 3ms/epoch - 3ms/step\n",
      "Epoch 193/200\n",
      "1/1 - 0s - loss: 0.1029 - accuracy: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 194/200\n",
      "1/1 - 0s - loss: 0.1010 - accuracy: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 195/200\n",
      "1/1 - 0s - loss: 0.0991 - accuracy: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 196/200\n",
      "1/1 - 0s - loss: 0.0973 - accuracy: 1.0000 - 3ms/epoch - 3ms/step\n",
      "Epoch 197/200\n",
      "1/1 - 0s - loss: 0.0955 - accuracy: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 198/200\n",
      "1/1 - 0s - loss: 0.0938 - accuracy: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 199/200\n",
      "1/1 - 0s - loss: 0.0921 - accuracy: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 200/200\n",
      "1/1 - 0s - loss: 0.0905 - accuracy: 1.0000 - 3ms/epoch - 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e9763eabc8>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#모델 설계하기\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Dense, SimpleRNN\n",
    "\n",
    "#embedding 인수 : input_dim(입력 크기), output_dim(출력크기), input_length(입력 데이터의 길이)\n",
    "#단어를 밀집벡터로 만드는 일을 수행한다. 정수 인코딩이 된 단어들을 입력으로 받아 수행한다. 단어를 랜덤한 값을 가지는\n",
    "#밀집 벡터로 변환한 뒤에, 인공신경망의 가중치를 학습하는 것과 같은 방식으로 단어 벡터를 학습하는 방법을 사용한다.\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 10, input_length = max_len - 1))\n",
    "model.add(SimpleRNN(32))\n",
    "model.add(Dense(vocab_size, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(x,y,epochs=200,verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "경마장에 있는 말이 뛰고 있다\n",
      "그의 말이 법이다\n",
      "가는 말이 고와야 오는 말이 곱다\n"
     ]
    }
   ],
   "source": [
    "def sentence_generation(model, t, current_word, n): #모델, 토크나이저, 현재 단어, 반복할 횟수\n",
    "    init_word = current_word # 처음 들어온 단어도 마지막에 같이 출력하기위해 저장\n",
    "    sentence = ''\n",
    "    for _ in range(n): #n번 반복\n",
    "        encoded = t.texts_to_sequences([current_word])[0] # 현재 단어에 대한 정수 인코딩\n",
    "        encoded = pad_sequences([encoded], maxlen=5, padding='pre') #데이터에 대한 패딩\n",
    "        result = model.predict(encoded, verbose=0)\n",
    "        predicted = result.argmax(axis=-1)\n",
    "        for word, index in t.word_index.items():\n",
    "            if index == predicted: #만약 예측한 단어와 인덱스와 동일한 단어가 있다면\n",
    "                break #해당 단어가 예측 단어이므로 break\n",
    "        current_word = current_word + ' ' + word\n",
    "        sentence = sentence + ' ' + word # 예측 단어를 문장에 저장\n",
    "    sentence = init_word + sentence\n",
    "    return sentence\n",
    "\n",
    "print(sentence_generation(model, t, '경마장에', 4))\n",
    "print(sentence_generation(model, t, '그의', 2)) #2번 예측\n",
    "print(sentence_generation(model, t, '가는', 5)) #5번 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.9 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "90ac13e2ffd2fb0a306c90461e8e391bceeb8ea777ddbefad745a048bb7968fd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
